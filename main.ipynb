{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import spacy\n",
    "import torchtext\n",
    "from torchtext.data import Field\n",
    "import numpy as np\n",
    "import json\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading spacy for tokenizing and stemme for stemming of the data\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punc =['?',',','.','_','!']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the tokenizer and the stemmer function\n",
    "def tok_eng(text):\n",
    "    return [(tok.text) for tok in spacy_eng.tokenizer(text)]\n",
    "def stemer(text):\n",
    "    return [stemmer.stem(word) for word in text if word  not in remove_punc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['organ', 'the', 'organ', 'in', 'the', 'human', 'bodi', 'and']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing the working of the stemer\n",
    "text = \"Organizing the organ in the Human body, and ? \"\n",
    "tex= tok_eng(text)\n",
    "\n",
    "stemer(tex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating bag of words for model training\n",
    " \n",
    "def bag_of_words(input_words, all_words):\n",
    "    tokenize = tok_eng(input_words)\n",
    "    stemmed_words = stemer(tokenize)\n",
    "    input_array = np.zeros(len(all_words), dtype=np.float32)\n",
    "    for i, word in enumerate(all_words):\n",
    "        if word in stemmed_words:\n",
    "            input_array[i]=1\n",
    "    return input_array    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['do', 'doe', 'funni', 'get', 'good', 'goodby', 'have', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'is', 'item', 'joke', 'kind', 'know', 'later', 'long', 'lot', 'mastercard', 'me', 'my', 'of', 'onli', 'pay', 'paypal', 'see', 'sell', 'ship', 'someth', 'take', 'tell', 'thank', 'that', 'there', 'what', 'when', 'which', 'with', 'you']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking out bagging function as it will be the input to the nn\n",
    "inp = \"hi\"\n",
    "out = ['do', 'doe', 'funni', 'get', 'good', 'goodby', 'have', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'is', 'item', 'joke', 'kind', 'know', 'later', 'long', 'lot', 'mastercard', 'me', 'my', 'of', 'onli', 'pay', 'paypal', 'see', 'sell', 'ship', 'someth', 'take', 'tell', 'thank', 'that', 'there', 'what', 'when', 'which', 'with', 'you']\n",
    "\n",
    "inp = tok_eng(inp)\n",
    "inp = ' '.join(inp)\n",
    "print(out)\n",
    "bag_of_words(inp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading our json file \n",
    "with open('data.json','r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['availability',\n",
       " 'capabilities',\n",
       " 'delivery',\n",
       " 'funny',\n",
       " 'goodbye',\n",
       " 'greeting',\n",
       " 'items',\n",
       " 'payments',\n",
       " 'personal_info',\n",
       " 'thanks']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mapping our datas in in the json file to make the ultimate maapping of tags and it's response for our all words\n",
    "\n",
    "all_words = []\n",
    "tags = []\n",
    "word_tag_map =[]\n",
    "\n",
    "for datas in data['intents']:\n",
    "    tag = datas['tag']  \n",
    "    tags.append(tag)\n",
    "\n",
    "    for pattern in datas['patterns']:\n",
    "        stemming = stemer(tok_eng(pattern))\n",
    "        all_words.extend(stemming)      \n",
    "        word_tag_map.append((stemming, tag))\n",
    "        \n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World !\n"
     ]
    }
   ],
   "source": [
    "my_list = ['Hello', 'World', '!']\n",
    "\n",
    "# Convert the list to a string with a space (' ') separator\n",
    "my_string = ' '.join(my_list)\n",
    "\n",
    "print(my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create training data\n",
    "X_train = []\n",
    "y_train = []\n",
    "for (pattern_sentence, tag) in word_tag_map:\n",
    "    # X: bag of words for each pattern_sentence\n",
    "    pattern_sentence = ' '.join(pattern_sentence)\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    X_train.append(bag)\n",
    "    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)\n",
    "print(y_train[1] ) \n",
    "(X_train[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 35\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print(len(X_train),len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our dataset\n",
    "\n",
    "class Bot(Dataset):\n",
    "    def __init__(self):\n",
    "        self.samples = len(X_train)\n",
    "        self.inp = X_train\n",
    "        self.output = y_train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inp[index], self.output[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.samples\n",
    "dataset = Bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a neural network for training of only 3 layers\n",
    "\n",
    "class ChatBot(nn.Module):\n",
    "    def __init__(self, inp_size, hidden_size, output_size) :\n",
    "        super(ChatBot,self).__init__()\n",
    "        self.input_size = nn.Linear(inp_size, hidden_size)\n",
    "        self.hidden_size = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output_size=nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x1= self.input_size(x)\n",
    "        x1=self.relu(x1)\n",
    "        x1= self.hidden_size(x1)\n",
    "        x1=self.relu(x1)\n",
    "        x1= self.output_size(x1)\n",
    "        return x1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 10\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters \n",
    "num_epochs = 1000\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "input_size = len(X_train[0])\n",
    "hidden_size = 10\n",
    "output_size = len(tags)\n",
    "print(input_size, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]]),\n",
       " tensor([5, 8, 2, 5, 4, 3, 0, 7], dtype=torch.int32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using dataloader for subjecting into training\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=8,\n",
    "                          shuffle=True)\n",
    "test = next(iter(train_loader))\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatBot(\n",
       "  (input_size): Linear(in_features=66, out_features=10, bias=True)\n",
       "  (hidden_size): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (output_size): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatBot(input_size, hidden_size, output_size ).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the optim and lossfun\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [00:00<00:17, 58.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 1000], Loss: 0.0003\n",
      "===> saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 106/1000 [00:01<00:13, 67.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 100 / 1000], Loss: 0.0006\n",
      "===> saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 214/1000 [00:03<00:11, 70.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 200 / 1000], Loss: 0.0002\n",
      "===> saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 310/1000 [00:04<00:10, 67.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 300 / 1000], Loss: 0.0003\n",
      "===> saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 412/1000 [00:06<00:08, 70.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 400 / 1000], Loss: 0.0000\n",
      "===> saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 509/1000 [00:07<00:07, 65.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 500 / 1000], Loss: 0.0000\n",
      "===> saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 613/1000 [00:09<00:05, 68.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 600 / 1000], Loss: 0.0001\n",
      "===> saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 713/1000 [00:10<00:04, 68.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 700 / 1000], Loss: 0.0000\n",
      "===> saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 810/1000 [00:12<00:02, 66.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 800 / 1000], Loss: 0.0001\n",
      "===> saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 910/1000 [00:13<00:01, 69.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 900 / 1000], Loss: 0.0000\n",
      "===> saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:15<00:00, 66.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Now training our model\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for (words, labels) in train_loader:\n",
    "        words = words.to(device)\n",
    "        labels = labels.to(dtype=torch.long).to(device)\n",
    "#         # Forward pass\n",
    "        outputs = model(words)    \n",
    "        # if y would be one-hot, we must apply\n",
    "        # labels = torch.max(labels, 1)[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch%100 ==0:\n",
    "        print(f\"[Epoch {epoch} / {num_epochs}], Loss: {loss.item():.4f}\")\n",
    "        checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict(), \"epoch\": epoch}\n",
    "        print(\"===> saving\")\n",
    "        torch.save(checkpoint, \"model.pth\")\n",
    "\n",
    "\n",
    "print(f'final loss: {loss.item():.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat! (type 'quit' to exit)\n",
      "Hi I'm jarvis, Ask me anything?\n",
      "Me: hello\n",
      "Jarvis: Hello, thanks for visiting\n",
      "Me: hi\n",
      "Jarvis: Hi there, how can I help?\n",
      "Me: what is your name\n",
      "Jarvis: See you later, thanks for visiting\n",
      "Me: what is your name\n",
      "Jarvis: See you later, thanks for visiting\n",
      "Me: name\n",
      "Jarvis: See you later, thanks for visiting\n",
      "Me: when are you available\n",
      "Jarvis: I am available 24/7 to assist you.\n",
      "Me: ??\n",
      "Jarvis: Bye! Come back again soon.\n",
      "Me: slow\n",
      "Jarvis: Have a nice day\n",
      "Me: hello\n",
      "Jarvis: Hey :-)\n",
      "Me: what are your service\n",
      "Jarvis: I do not understand...\n",
      "Me: what service can you give me\n",
      "Jarvis: My capabilities include answering queries, providing information, and offering assistance on various topics.\n",
      "Me: avaibility\n",
      "Jarvis: Have a nice day\n",
      "Me: s\n",
      "Jarvis: See you later, thanks for visiting\n",
      "Me: quit\n"
     ]
    }
   ],
   "source": [
    "#Testing our model\n",
    "\n",
    "torch.load('model.pth')\n",
    "model.eval()\n",
    "\n",
    "bot_name = \"Jarvis\"\n",
    "print(\"Let's chat! (type 'quit' to exit)\")\n",
    "print(\"Hi I'm jarvis, Ask me anything?\")\n",
    "while True:\n",
    "    # sentence = \"do you use credit cards?\"\n",
    "    sentence = input(\"You: \")\n",
    "    print(f\"Me: {sentence}\")\n",
    "    if sentence == \"quit\":\n",
    "        break\n",
    "\n",
    "    # sentence = tok_eng(sentence)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in data['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
    "    else:\n",
    "        print(f\"{bot_name}: I do not understand...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
